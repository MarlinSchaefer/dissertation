\chapter{Chapter Descriptions and Authorship Clarifications}
This thesis is based on a set of publications.
\begin{itemize}
	\item Chapter \ref{ch:bns} -- a summary of \cite{Schafer:2020kor} -- contains a novel method to search for \acrshort{bns} mergers using a deep neural network.
	\item Chapter \ref{ch:forecasting} -- a summary of \cite{Nitz:2020vym} -- evaluates the capability of a state-of-the-art analysis for generating pre-merger alerts and sky-localizations for \acrshort{gw}s from \acrshort{bns} mergers.
	\item Chapter \ref{ch:training_strats} -- a reprint of \cite{Schafer:2021fea} -- contains a reanalysis of an existing deep learning search for binary black hole (\acrshort{bbh}) signals at low \acrshort{far}s, extends the method to work with even lower \acrshort{far}s, and tests the influence of different training strategies on the detection performance.
	\item Chapter \ref{ch:cnn_coinc} -- a reprint of \cite{Schafer:2021cml} -- tests the applicability of single detector deep learning search algorithms in a coincidence multi-detector search.
	\item Chapter \ref{ch:mlgwsc1} -- a reprint of \cite{Schafer:2022dxv} -- contains the results of a global mock data challenge that assesses the current capability of \acrshort{ml} search algorithms for \acrshort{bbh} signals and compares them to state-of-the-art pipelines.
\end{itemize}
The works \cite{Schafer:2020kor}, \cite{Schafer:2021fea}, and \cite{Schafer:2021cml} are published in Physical Review D, the work \cite{Nitz:2020vym} is published in Astrophysical Journal Letters, and the work \cite{Schafer:2022dxv} is accepted by Physical Review D. Below I will give a more detailed summary of each chapter in this thesis, including those not based on the works listed above, and will clarify my contribution to each work. A full list of publications I was involved in can be found in appendix \ref{app:publications}.

Chapter \ref{ch:foundations} gives an overview of the foundations required to understand the content of this thesis. Section \ref{sec:gw_main} discusses the theory of \acrshort{gw} generation and the resulting waveforms. It summarizes the treatment from the approximation of linearized gravity up to complex modern waveform models. Section \ref{sec:cbc_searches} treats various aspects used in current day \acrshort{gw} detection, touching on the subjects of \acrshort{gw} detectors and their noise characteristics, signal detection algorithms, as well as the significance of detections. Section \ref{sec:deep_learning} provides an introduction to deep learning. It discusses the mathematical foundations of neural networks and how they can be trained. Section \ref{sec:ml-gw-hist} gives an overview of recent works relevant to the field of \acrshort{ml} based \acrshort{gw} data analysis. The foundations discussed in chapter \ref{ch:foundations} are also touched upon to various degrees of depth in chapters \ref{ch:bns}, \ref{ch:training_strats}, \ref{ch:cnn_coinc}, and \ref{ch:mlgwsc1}. However, chapter \ref{ch:foundations} provides more detail and background, as well as tying the works into the greater context of existing research. It was entirely written by myself with some help in proof reading.

In chapter \ref{ch:bns} I summarize the results of \cite{Schafer:2020kor} and present the differences to my master thesis~\cite{Schaefer:2019:MSC}, which the paper is based on. The study introduces a procedure to reduce the amount of data that needs to be processed for the detection of \acrshort{gw} signals from \acrshort{bns} mergers. This procedure is then utilized to build a novel multi-detector search algorithm that uses deep neural networks. The resulting algorithm significantly improves on the performance of a previous deep learning based algorithm for the most commonly expected signal strengths and at low \acrshort{far}s. It also stresses the importance of testing machine learning based algorithms at \acrshort{far}s $\leq 1$ per month for the application in production analyses. The topic was suggested by my master supervisors F. Ohme and A. H. Nitz, who proposed to use multiple sampling rates. My contribution was to create training and testing data, optimize the neural network architecture, define the process of sampling the data at multiple rates, and write the implementation. The paper was written by myself with close guidance from A. H. Nitz and F. Ohme.

Chapter \ref{ch:forecasting} summarizes the work done in \cite{Nitz:2020vym}. The paper investigates the prospects of detecting \acrshort{gw} signals from compact binary coalescences before the merger for current and planned detector networks. It also discusses how well these pre-merger detections can be localized on the sky, to allow for prompt electromagnetic follow-up observations. It finds that future \acrshort{gw} observatories will be capable of providing several minutes of early warning for sources localized to $< 100 \text{deg}^2$ in the sky. The research was led by A. H. Nitz, who also suggested the topic. I provided the code to perform a high-level analysis of the detectability of signals based on a network signal-to-noise ratio threshold. The code calculates the network signal-to-noise ratio for post-Newtonian waveforms truncated at different high-frequency cutoffs. This also allowed for the creation of a suitable template bank for a full analysis on mock data. The draft of the paper was written by A. H. Nitz and T. Dal Canton. I contributed to the body of the publication by proof reading the draft.

Chapter \ref{ch:training_strats} is a reprint of \cite{Schafer:2021fea}. It reproduces the results of \cite{Gabbard:2017lja} and extends them to lower \acrshort{far}s. From this baseline, the study investigates the influence on the sensitivity of different training strategies for deep learning \acrshort{gw} search algorithms. It is found that the particular strategy has little influence, as long as sufficiently difficult examples are used. Furthermore, a new output statistic for the networks is presented which avoids numerical instabilities that have made it previously impossible to test the network at production level \acrshort{far}s. The idea for the study was developed by myself in collaboration with O. Zelenka and in close correspondence with A. H. Nitz, F. Ohme, and B. Brügmann. The paper draft was written by myself with some sections being contributed by O. Zelenka. A. H. Nitz, F. Ohme, and B. Brügmann helped with revisions of the draft and made comments to improve the evaluation.

Chapter \ref{ch:cnn_coinc} is a reprint of \cite{Schafer:2021cml}. The study tests the applicability of deep learning \acrshort{gw} search algorithms trained on a single detector in a coincidence analysis. It compares the results from a time-coincidence analysis of the deep learning results with a state-of-the-art matched filter based production search. We find that the application works seamlessly but falls short in sensitivity compared to matched filtering due to the inability of comparing signal parameters across multiple detectors. We also highlight the usefulness of our approach in probing deep learning searches at \acrshort{far}s $<100$ per year. The paper, furthermore, presents a combined ranking statistic based on the single detector network output presented in \cite{Schafer:2021fea}. The study was entirely proposed by myself, with some input on the details from A. H. Nitz. Accordingly, the draft of the paper was written by myself with minor revisions by A. H. Nitz.

Chapter \ref{ch:mlgwsc1} is a reprint of \cite{Schafer:2022dxv}. It discusses the first machine learning gravitational-wave search mock data challenge and its results. Several research groups around the world were asked to submit \acrshort{gw} search algorithms which were subsequently evaluated on common data sets using common metrics. The goal of the challenge was the evaluation of different machine learning based algorithms to create a reference and objective comparison between the different submissions, as well as to state-of-the-art production searches. Due to the open source policy of the challenge, its resources are intended to be a base of comparison also for future algorithms. Furthermore, the most promising future research areas for machine learning search algorithms were identified from the results. The project was suggested by A. H. Nitz. The organization of the challenge, including meetings, communication, and the development of the public codebase, was primarily in my responsibility. O. Zelenka helped with PyTorch implementations and provided tutorials. Details of the challenge, including the parameters of the data sets, were discussed with the organization team consisting of O. Zelenka, A. H. Nitz, B. Brügmann, F. Ohme, and myself as well as the scientific advisers E. Cuoco, E. A. Huerta, and C. Messenger. The initial paper draft was written by myself, with revisions being made by all authors. An exception to this are the descriptions of the submissions, which were written by the groups.

Chapter \ref{ch:bosch} is a summary of a voluntary internship I did at Bosch Hildesheim, to gain insights into the non-academic development process of \acrshort{ml} algorithms. It is separate from the rest of the thesis, as it discussed self-supervised learning algorithms for object detection applications. For this reason, it includes a short overview of the required foundations of object detection and self-supervised learning in the context of computer vision. Afterward, my research at Bosch is summarized, which tried to test an existing  self-supervised learning framework and develop a new one. Both approaches turned out to yield negative results, as we could not demonstrate an improvement over randomly initialized networks. The entire chapter was written by myself with some help in proof reading.

Chapter \ref{ch:conclusions} concludes this thesis and gives an outlook into possible further research topics.
